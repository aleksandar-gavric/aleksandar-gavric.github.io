<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Aleksandar Gavrić</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Aleksandar Gavrić
                </p>
                <p>
                  I am a PhD researcher at <a href="https://www.tuwien.at/en/">TU Wien</a>, working at the 
                  <a href="https://big.tuwien.ac.at/">Business Informatics Group</a> under 
                  Prof. <a href="https://model-engineering.info/">Dominik Bork</a> and Prof. <a href="https://www.erikproper.eu/">Henderik Proper</a>. 
                  <br><br>
                  My work focuses on 
                  <strong>world-model construction</strong> by integrating 
                  <strong>multimodal process mining</strong>, 
                  <strong>mixed-reality simulation</strong>, and 
                   <strong>video generation models</strong> 
                  to capture and model <strong>tacit expertise</strong>.
                  <br><br>
                  Previously, I worked with the <a href="https://kavrakilab.org/">Lydia Kavraki's</a>, and <a href="https://astro.rice.edu">Edward Knightly's</a> Labs (Rice University), 
                  <a href="https://www.mackenziemathislab.org/">Mackenzie Mathis</a> (EPFL) as a TA in the 
                  <a href="https://www.deeplabcut.org/">DeepLabCut</a> course, <a href="https://www.stanimirovic.info/">Aleksandar Stanimirovic</a> (Univesity of Nis), 
                  and founded <a href="https://ai-for-hotels.com/">AI-for-Hotels.com</a>, 
                  where I developed RAG, robotics and holographic systems. 
          
                </p>
                
                <p style="text-align:center">
                  <a href="mailto:gavric97@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/AleksandarGavric-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/AleksandarGavric-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=cFzfBfAAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/AcaGavric">X.com</a> &nbsp;/&nbsp;
                  <a href="https://github.com/aleksandargavric">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/AleksandarGavric.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/AleksandarGavric.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in conceptual modeling, world-model construction,  computer vision, deep learning, generative AI, multimodal representation learning, and differentiable algorithms for <strong>discovering, understanding</strong> and <strong>simulating real-world processes</strong>. 
                  Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <!-- 1. Petri Net Structure-Driven Video Generation -->
    <tr onmouseout="pnsdvg_stop()" onmouseover="pnsdvg_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="pnsdvg_image">
            <img src="images/publications/2025_petri_net_video_generation_after.png" width="100%">
          </div>
          <img src="images/publications/2025_petri_net_video_generation_before.png" width="100%">
        </div>
        <script>
          function pnsdvg_start(){ document.getElementById('pnsdvg_image').style.opacity="1"; }
          function pnsdvg_stop(){ document.getElementById('pnsdvg_image').style.opacity="0"; }
          pnsdvg_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://what-makes-good-video.github.io/assets/21_Petri_Net_Structure_Driven_.pdf">
          <span class="papertitle">Petri Net Structure-Driven Video Generation (Short Paper)</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>NeurIPS Workshop “What Makes a Good Video”, 2025</em>
        <p>
          Built a <b>structure-conditioned video generation</b> pipeline using Petri nets as <b>causal scaffolding</b> for diffusion models.
        </p>
      </td>
    </tr>

    

<tr onmouseout="phd_mmdamr_stop()" onmouseover="phd_mmdamr_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id="phd_mmdamr_video">
        <video width="100%" height="100%" muted autoplay loop>
          <source src="images/publications/phd_mmdamr.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <img src="images/publications/phd_mmdamr.png" width="160">
    </div>

    <script type="text/javascript">
      function phd_mmdamr_start() {
        document.getElementById('phd_mmdamr_video').style.opacity = "1";
      }
      function phd_mmdamr_stop() {
        document.getElementById('phd_mmdamr_video').style.opacity = "0";
      }
      phd_mmdamr_stop();
    </script>
  </td>

  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://conferences.big.tuwien.ac.at/biweek2025/data/AleksandarGavric_PhD_Dissertation.pdf">
      <span class="papertitle">
      Enhancing Conceptual Modeling through Multimodal Data Analysis and Mixed Reality
    </span>
  </a>
    <br>
    <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric">
      <strong>Aleksandar&nbsp;Gavric</strong>
    </a>
    <br>
    <em>Doctoral Dissertation</em>
    <p>
      A unified research framework integrating <b>multimodal process mining</b> with 
      <b>mixed-reality elicitation</b>.  
      The thesis models how real-world work unfolds by combining <b>video</b>, <b>audio</b>, 
      <b>interaction logs</b>, <b>sensor data</b>, and immersive <b>MR simulations</b> to extract tacit expertise and 
      build next-generation conceptual models.
    </p>
  </td>
</tr>



    <!-- 2. Enrichment of Conceptual Models with Multimodal Data -->
    <tr onmouseout="isd25_stop()" onmouseover="isd25_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="isd25_image">
            <img src="images/publications/2025_enrich_conceptual_models_after.png" width="100%">
          </div>
          <img src="images/publications/2025_enrich_conceptual_models_before.png" width="100%">
        </div>
        <script>
          function isd25_start(){ document.getElementById('isd25_image').style.opacity="1"; }
          function isd25_stop(){ document.getElementById('isd25_image').style.opacity="0"; }
          isd25_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://model-engineering.info/publications/papers/ISD2025-Web.pdf">
          <span class="papertitle">Towards the Enrichment of Conceptual Models with Multimodal Data</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>ISD 2025</em>
        <p>
          Proposed embedding-based <b>multimodal fusion</b> and <b>crossmodal alignment</b> to enrich conceptual models.
        </p>
      </td>
    </tr>    

    <!-- 4. Turning Process Models into Videos -->
    <tr onmouseout="cbi25_video_stop()" onmouseover="cbi25_video_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="cbi25_video_image">
            <video width="100%" height="100%" muted autoplay loop>
              <source src="images/publications/2025_cbi_video_generation_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
           </div>
          <img src="images/publications/2025_cbi_video_generation_before.png" width="100%">
        </div>
        <script>
          function cbi25_video_start(){ document.getElementById('cbi25_video_image').style.opacity="1"; }
          function cbi25_video_stop(){ document.getElementById('cbi25_video_image').style.opacity="0"; }
          cbi25_video_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://model-engineering.info/publications/papers/CBI25-Video-Generation.pdf">
          <span class="papertitle">Turning Process Models into Videos</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>CBI 2025</em>
        <p>
          Converts BPMN models into executable <b>synthetic video animations</b> for automated evaluation.
        </p>
      </td>
    </tr>


    <tr onmouseout="dke_align_stop()" onmouseover="dke_align_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id="dke_align_image">
            <img src="images/publications/2025_dke_alignment_after.png" width="100%">
          </div>
          <img src="images/publications/2025_dke_alignment_before.png" width="100%">
        </div>
        <script>
          function dke_align_start(){ document.getElementById('dke_align_image').style.opacity="1"; }
          function dke_align_stop(){ document.getElementById('dke_align_image').style.opacity="0"; }
          dke_align_stop();
        </script>
      </td>
    
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="./data/Aligning_CM_and_AI__Models.pdf">
          <span class="papertitle">
          Aligning AI Model’s Knowledge and Conceptual Model’s Symbols
        </span></a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar&nbsp;Gavric</strong></a>, 
        <a href="https://model-engineering.info/">Dominik&nbsp;Bork</a>, 
        <a href="https://www.erikproper.eu/">Henderik&nbsp;A.&nbsp;Proper</a>
        <br>
        <em>Data &amp; Knowledge Engineering (submitted), 2025</em>
        <p>
          Proposes an alignment framework that tunrs <b>multimodal embeddings</b> into 
          <b>formal conceptual model symbols</b>, enabling explainability, traceability, and hybrid reasoning in 
          mixed human–AI modeling workflows.
        </p>
      </td>
    </tr>



    

    
    <!-- 3. Petri Net of Thoughts -->
    <tr onmouseout="pnthoughts_stop()" onmouseover="pnthoughts_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="pnthoughts_image">
            <img src="images/publications/2025_petri_net_of_thoughts_after.png" width="100%">
          </div>
          <img src="images/publications/2025_petri_net_of_thoughts_before.png" width="100%">
        </div>
        <script>
          function pnthoughts_start(){ document.getElementById('pnthoughts_image').style.opacity="1"; }
          function pnthoughts_stop(){ document.getElementById('pnthoughts_image').style.opacity="0"; }
          pnthoughts_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://www.erikproper.eu/publications/EP-2025-05-15-14-29-20.pdf">
          <span class="papertitle">Petri Net of Thoughts: A Structure-Enhanced Prompting Approach for Process-Aware AI</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>EMISA 2025</em>
        <p>
          Introduced a Petri net–guided <b>prompting paradigm</b> improving <b>process-aware reasoning</b>.
        </p>
      </td>
    </tr>

    

    <!-- 5. Beyond Logs: AI’s Internal Representations as the New Process Evidence -->
    <tr onmouseout="beyondlogs_stop()" onmouseover="beyondlogs_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="beyondlogs_image">
            <img src="images/publications/2025_bpm_beyond_logs_after.png" width="100%">
          </div>
          <img src="images/publications/2025_bpm_beyond_logs_before.png" width="100%">
        </div>
        <script>
          function beyondlogs_start(){ document.getElementById('beyondlogs_image').style.opacity="1"; }
          function beyondlogs_stop(){ document.getElementById('beyondlogs_image').style.opacity="0"; }
          beyondlogs_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://model-engineering.info/publications/papers/BPM25-Forum-BeyondLogs.pdf">
          <span class="papertitle">Beyond Logs: AI’s Internal Representations as the New Process Evidence</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>BPM 2025</em>
        <p>
          Defined process mining on <b>latent AI representations</b>; introduced <b>relaxed discovery</b> and <b>conformance checking</b>.
        </p>
      </td>
    </tr>

    <tr onmouseout="vienna_comics_stop()" onmouseover="vienna_comics_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id="vienna_comics_image">
            <video width="100%" height="100%" muted autoplay loop>
              <source src="images/publications/2025_vienna_comics_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <img src="images/publications/2025_vienna_comics_before.png" width="100%">
        </div>
        <script>
          function vienna_comics_start(){ document.getElementById('vienna_comics_image').style.opacity="1"; }
          function vienna_comics_stop(){ document.getElementById('vienna_comics_image').style.opacity="0"; }
          vienna_comics_stop();
        </script>
      </td>
    
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="./data/ViEnNa_Comic-like_Process_Models.pdf"><span class="papertitle">
          Comics as Process Model Notation: Blending Object-Centric Event Logs and Multimodal Data in Visually Enhanced Narratives
        </span></a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar&nbsp;Gavric</strong></a>, 
        <a href="https://model-engineering.info/">Dominik&nbsp;Bork</a>, 
        <a href="https://www.erikproper.eu/">Henderik&nbsp;A.&nbsp;Proper</a>
        <br>
        <em>The Process Science (submitted), 2025</em>
        <p>
          Introduces <b>ViEnNa comics</b> as a process-model notation that combines <b>object-centric event logs</b> and 
          <b>multimodal evidence</b> into narrative visual diagrams enabling richer, more intuitive process understanding.
        </p>
      </td>
    </tr>



    <!-- 6. Surgery AI: Multimodal Process Mining & Mixed Reality (ZEUS 2025) -->
    <tr onmouseout="surgeryai_stop()" onmouseover="surgeryai_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="surgeryai_image">
            <img src="images/publications/2025_zeus_surgery_ai_after.png" width="100%">
          </div>
          <img src="images/publications/2025_zeus_surgery_ai_before.png" width="100%">
        </div>
        <script>
          function surgeryai_start(){ document.getElementById('surgeryai_image').style.opacity="1"; }
          function surgeryai_stop(){ document.getElementById('surgeryai_image').style.opacity="0"; }
          surgeryai_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://zeus2025.pi.uni-bamberg.de/files/pre-proceedings-zeus2025.pdf#page=51">
          <span class="papertitle">Surgery AI: Multimodal Process Mining & Mixed Reality</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>ZEUS 2025</em>
        <p>
          Real-time surgical <b>multimodal process mining</b> and <b>MR-guided conformance checking</b>.
        </p>
      </td>
    </tr>

    <!-- --- 2024 --- -->

    <!-- 8. How Does UML Look and Sound? Using AI to Interpret UML Diagrams Through Multimodal Evidence -->
    <tr onmouseout="er2024_uml_stop()" onmouseover="er2024_uml_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="er2024_uml_image">
            <img src="images/publications/2024_er_uml_multimodal_after.png" width="100%">
          </div>
          <img src="images/publications/2024_er_uml_multimodal_before.png" width="100%">
        </div>
        <script>
          function er2024_uml_start(){ document.getElementById('er2024_uml_image').style.opacity="1"; }
          function er2024_uml_stop(){ document.getElementById('er2024_uml_image').style.opacity="0"; }
          er2024_uml_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://www.erikproper.eu/publications/EP-2024-11-15-17-51-29.pdf">
          <span class="papertitle">How Does UML Look and Sound? Using AI to Interpret UML Diagrams Through Multimodal Evidence</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>ER 2024 Workshops</em>
        <p>
          Applied vision–language models to relate UML diagram elements with synthetic visual or acoustic evidence; introduced a user study linking UML fragments to verbal descriptions and observed interactions.
        </p>
      </td>
    </tr>


    <!-- 7. Stakeholder-specific jargon-based representation of multimodal data within business process -->
    <tr onmouseout="poem24_jargon_stop()" onmouseover="poem24_jargon_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="poem24_jargon_image">
            <img src="images/publications/2024_poem_jargon_multimodal_after.png" width="100%">
          </div>
          <img src="images/publications/2024_poem_jargon_multimodal_before.png" width="100%">
        </div>
        <script>
          function poem24_jargon_start(){ document.getElementById('poem24_jargon_image').style.opacity="1"; }
          function poem24_jargon_stop(){ document.getElementById('poem24_jargon_image').style.opacity="0"; }
          poem24_jargon_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://www.erikproper.eu/publications/EP-2024-12-19-14-22-18.pdf">
          <span class="papertitle">Stakeholder-specific jargon-based representation of multimodal data within business process</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>PoEM 2024 (Companion Proceedings)</em>
        <p>
          Designed NLP pipelines that translate multimodal observations into stakeholder-specific jargon, enabling domain-adaptive representation and improved explainability.
        </p>
      </td>
    </tr>

    
    <!-- 9. Enriching Business Process Event Logs with Multimodal Evidence -->
    <tr onmouseout="poem24_eventlogs_stop()" onmouseover="poem24_eventlogs_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="poem24_eventlogs_image">
            <video width="100%" height="100%" muted autoplay loop>
              <source src="images/publications/2024_poem_eventlogs_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <img src="images/publications/2024_poem_eventlogs_before.png" width="100%">
        </div>
        <script>
          function poem24_eventlogs_start(){ document.getElementById('poem24_eventlogs_image').style.opacity="1"; }
          function poem24_eventlogs_stop(){ document.getElementById('poem24_eventlogs_image').style.opacity="0"; }
          poem24_eventlogs_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://model-engineering.info/publications/papers/PoEM24-Gavric.pdf">
          <span class="papertitle">Enriching Business Process Event Logs with Multimodal Evidence</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>PoEM 2024</em>
        <p>
          Augmented traditional event logs with multimodal signals; developed crossmodal encoders to infer missing or tacit activities.
        </p>
      </td>
    </tr>


    <!-- 11. Modified SPICE-Compatible Model for VDMOS Transistors (IcETRAN 2024) -->
    <tr onmouseout="icetran24_vdmos_stop()" onmouseover="icetran24_vdmos_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="icetran24_vdmos_image">
            <img src="images/publications/2024_icetran_vdmos_after.png" width="100%">
          </div>
          <img src="images/publications/2024_icetran_vdmos_before.png" width="100%">
        </div>
        <script>
          function icetran24_vdmos_start(){ document.getElementById('icetran24_vdmos_image').style.opacity="1"; }
          function icetran24_vdmos_stop(){ document.getElementById('icetran24_vdmos_image').style.opacity="0"; }
          icetran24_vdmos_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://ieeexplore.ieee.org/document/10645094">
          <span class="papertitle">Modified SPICE-Compatible Model Integrating NBTI and Self-Heating Effects for VDMOS Transistors</span>
        </a>
        <br>
        Marjanović, M., Veljković, S., Mitrović, N., Živanović, E., 
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>, 
        & Danković, D.
        <br>
        <em>IcETRAN 2024</em>
        <p>
          Built physics-informed models predicting transistor degradation; combined simulation data with ML-supported curve-fitting for accuracy under thermal and stress conditions.
        </p>
      </td>
    </tr>

    
    <!-- 10. Multimodal Process Mining -->
    <tr onmouseout="cbi24_mmpm_stop()" onmouseover="cbi24_mmpm_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="cbi24_mmpm_image">
            <video width="100%" height="100%" muted autoplay loop>
              <source src="images/publications/2024_cbi_multimodal_process_mining_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
            </div>
          <img src="images/publications/2024_cbi_multimodal_process_mining_before.png" width="100%">
        </div>
        <script>
          function cbi24_mmpm_start(){ document.getElementById('cbi24_mmpm_image').style.opacity="1"; }
          function cbi24_mmpm_stop(){ document.getElementById('cbi24_mmpm_image').style.opacity="0"; }
          cbi24_mmpm_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://model-engineering.info/publications/papers/CBI-MultiModalProcessMining.pdf">
          <span class="papertitle">Multimodal Process Mining</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        <a href="https://model-engineering.info/">Dominik Bork</a>,
        <a href="https://www.erikproper.eu/">Henderik A. Proper</a>
        <br>
        <em>CBI 2024</em>
        <p>
          Formulated multimodal process mining as a representation-learning task; developed unified embeddings combining video, audio, and UI interactions for robust discovery under ambiguity.
        </p>
      </td>
    </tr>

    <!-- --- 2023 --- -->

    <!-- 12. Encoding Conceptual Models for Machine Learning: A Systematic Review -->
    <tr onmouseout="modelsc23_encoding_stop()" onmouseover="modelsc23_encoding_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="modelsc23_encoding_image">
            <img src="images/publications/2023_models_encoding_conceptual_models_after.png" width="100%">
          </div>
          <img src="images/publications/2023_models_encoding_conceptual_models_before.png" width="100%">
        </div>
        <script>
          function modelsc23_encoding_start(){ document.getElementById('modelsc23_encoding_image').style.opacity="1"; }
          function modelsc23_encoding_stop(){ document.getElementById('modelsc23_encoding_image').style.opacity="0"; }
          modelsc23_encoding_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://doi.org/10.1109/MODELS-C59198.2023.00094">
          <span class="papertitle">Encoding Conceptual Models for Machine Learning: A Systematic Review</span>
        </a>
        <br>
        Ali, S. J., <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>, Henderik A. Proper, & Dominik Bork
        <br>
        <em>MODELS-C 2023</em>
        <p>
          Surveyed ML-ready encodings of BPMN/UML/Petri nets; categorized graph-neural, image-based, and text-based approaches; highlighted open challenges in multimodal interoperability.
        </p>
      </td>
    </tr>

    <!-- 13. Enhancing process understanding through multimodal data analysis and extended reality -->
    <tr onmouseout="poem_edoc23_xr_stop()" onmouseover="poem_edoc23_xr_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="poem_edoc23_xr_image">
            <video width="100%" height="100%" muted autoplay loop>
              <source src="images/publications/2023_poem_xr_reenactments_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <img src="images/publications/2023_poem_xr_reenactments_before.png" width="100%">
        </div>
        <script>
          function poem_edoc23_xr_start(){ document.getElementById('poem_edoc23_xr_image').style.opacity="1"; }
          function poem_edoc23_xr_stop(){ document.getElementById('poem_edoc23_xr_image').style.opacity="0"; }
          poem_edoc23_xr_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://ceur-ws.org/Vol-3645/dc1.pdf">
          <span class="papertitle">Enhancing process understanding through multimodal data analysis and extended reality</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>
        <br>
        <em>PoEM / EDOC 2023 Companion Proceedings</em>
        <p>
          Demonstrated XR-based reenactments for generating high-quality multimodal logs; evaluated video-driven activity recognition for process discovery.
        </p>
      </td>
    </tr>

    <tr onmouseout="xr_oculo_vestibular_stop()" onmouseover="xr_oculo_vestibular_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id="xr_oculo_vestibular_image">
            <video width="100%" height="100%" muted autoplay loop>
              <source src="images/publications/2023_xr_oculo_vestibular_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
              </div>
          <img src="images/publications/2023_xr_oculo_vestibular_before.png" width="100%">
        </div>
        <script>
          function xr_oculo_vestibular_start(){ 
            document.getElementById('xr_oculo_vestibular_image').style.opacity="1"; 
          }
          function xr_oculo_vestibular_stop(){ 
            document.getElementById('xr_oculo_vestibular_image').style.opacity="0"; 
          }
          xr_oculo_vestibular_stop();
        </script>
      </td>
    
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/10315868">
          <span class="papertitle">
            A System for Detection and Tracking of Oculo-Vestibular Complications Associated with Extended Reality Headset Usage
          </span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar&nbsp;Gavric</strong></a>, 
        Merlinsky, E. A., 
        <a href="https://www.stanimirovic.info/">Aleksandar&nbsp;Stanimirović</a>
        <br>
        <em>MIEL 2023</em>, pp. 1–4. IEEE
        <p>
          Examined health issues associated with XR headset usage and introduced a system for detecting and 
          monitoring <b>ocular and vestibular complications</b>, including actionable guidance for prevention.
        </p>
      </td>
    </tr>

    
    <tr onmouseout="xr_adaptive_optics_stop()" onmouseover="xr_adaptive_optics_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id="xr_adaptive_optics_image">
            <video width="100%" height="100%" muted autoplay loop>
              <source src="images/publications/2023_xr_adaptive_optics_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
             </div>
          <img src="images/publications/2023_xr_adaptive_optics_before.png" width="100%">
        </div>
        <script>
          function xr_adaptive_optics_start(){ 
            document.getElementById('xr_adaptive_optics_image').style.opacity="1"; 
          }
          function xr_adaptive_optics_stop(){ 
            document.getElementById('xr_adaptive_optics_image').style.opacity="0"; 
          }
          xr_adaptive_optics_stop();
        </script>
      </td>
    
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/10315935">
          <span class="papertitle">
            Physics-Driven Methods for Adaptive Optics Effect in Extended Reality
          </span>
        </a>
        <br>
        Merlinsky, E. A., 
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar&nbsp;Gavric</strong></a>, 
        Stojković, H., 
        Živanović, E.
        <br>
        <em>MIEL 2023</em>, pp. 1–4. IEEE
        <p>
          Surveyed how <b>adaptive optics</b>, <b>eye-tracking</b>, and <b>light-field display physics</b> can enable 
          immersive XR experiences without traditional corrective lenses.
        </p>
      </td>
    </tr>
    

    <!-- --- 2022 --- -->

    <!-- 14. Real-Time Data Processing Techniques for a Scalable Spatial and Temporal Dimension Reduction -->
    <tr onmouseout="infoteh22_str_stop()" onmouseover="infoteh22_str_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="infoteh22_str_image">
            <img src="images/publications/2022_infoteh_spatial_temporal_reduction_after.png" width="100%">
          </div>
          <img src="images/publications/2022_infoteh_spatial_temporal_reduction_before.png" width="100%">
        </div>
        <script>
          function infoteh22_str_start(){ document.getElementById('infoteh22_str_image').style.opacity="1"; }
          function infoteh22_str_stop(){ document.getElementById('infoteh22_str_image').style.opacity="0"; }
          infoteh22_str_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://doi.org/10.1109/INFOTEH53737.2022.9751323">
          <span class="papertitle">Real-Time Data Processing Techniques for a Scalable Spatial and Temporal Dimension Reduction</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        Vujošević, D., Radosavljević, N., & Prvulović, P.
        <br>
        <em>INFOTEH 2022</em>
        <p>
          Showed experimentally how spatial and temporal dimension reduction of sensor streams can lead to more successful predictive models in different applications.
        </p>
      </td>
    </tr>

    <!-- --- 2021 --- -->

    <!-- 15. Identification of Air Pollution Sources using Predictive Models and Vehicular Sensor Networks -->
    <tr onmouseout="icist21_airpollution_stop()" onmouseover="icist21_airpollution_start()">
      <td style="padding:16px;width:20%;">
        <div class="one">
          <div class="two" id="icist21_airpollution_image">
            <img src="images/publications/2021_icist_airpollution_predictive_after.png" width="100%">
          </div>
          <img src="images/publications/2021_icist_airpollution_predictive_before.png" width="100%">
        </div>
        <script>
          function icist21_airpollution_start(){ document.getElementById('icist21_airpollution_image').style.opacity="1"; }
          function icist21_airpollution_stop(){ document.getElementById('icist21_airpollution_image').style.opacity="0"; }
          icist21_airpollution_stop();
        </script>
      </td>
      <td style="padding:8px;width:80%;">
        <a href="https://eventiotic.com/eventiotic/files/Papers/URL/d8e6ecec-3671-46a5-a2b8-2ae46f0f67a5.pdf">
          <span class="papertitle">Identification of Air Pollution Sources using Predictive Models and Vehicular Sensor Networks</span>
        </a>
        <br>
        <a href="https://informatics.tuwien.ac.at/people/aleksandar-gavric"><strong>Aleksandar Gavric</strong></a>,
        Stanimirović, A., & Stoimenov, L.
        <br>
        <em>ICIST 2021</em>
        <p>
          Designed and implemented a predictive ML model for a distributed system applying machine learning on data streams to estimate dominant pollution sources in real time.
        </p>
      </td>
    </tr>

	
    

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://conferences.big.tuwien.ac.at/caise2025/mmpm.php">Organizer, Program Chair, The 1st International Workshop on Multimodal Process Mining (MMPM) at CAiSE 2025;</a>
                <br>
                <a href="https://conferences.big.tuwien.ac.at/caise2025/">Web Chair, CAiSE 2025</a>
                <br>
                <a href="https://conferences.big.tuwien.ac.at/biweek2024/cbi.php">Web Chair, CBI 2024</a>
                <br>
                <a href="https://conferences.big.tuwien.ac.at/biweek2024/edoc.php">Web Chair, EDOC 2024</a>
                <br>
                <a href="https://conferences.big.tuwien.ac.at/poem2023/">Web Chair, PoEM+EDEWC 2023</a>
                
  
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://tiss.tuwien.ac.at/course/courseDetails.xhtml?courseNr=194143&semester=2025W">University Assistant, Information Systems Engineering, TU Wien, Fall 2025</a>
                <br>
                <a href="https://tiss.tuwien.ac.at/course/courseDetails.xhtml?courseNr=194195&semester=2025S">University Assistant, Advanced Model Engineering, TU Wien, Summer 2025</a>
                <br>
                <a href="https://tiss.tuwien.ac.at/course/courseDetails.xhtml?courseNr=194143&semester=2024W">University Assistant, Information Systems Engineering, TU Wien, Fall 2024</a>
                <br>
                <a href="https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=7946&dsrid=392&semester=2024W&courseNr=194152">University Assistant, Enterprise &amp; Process Engineering, TU Wien, Fall 2024</a>
                <br>
                <a href="https://tiss.tuwien.ac.at/course/courseDetails.xhtml?semester=2025S&courseNr=194153">University Assistant, Business-IT-Alignment, TU Wien, Summer 2024</a>
                <br>
                <a href="https://tiss.tuwien.ac.at/course/courseDetails.xhtml?courseNr=194143&semester=2023W">University Assistant, Information Systems Engineering, TU Wien, Fall 2023</a>
                <br>
                <a href="https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=7946&dsrid=392&semester=2023W&courseNr=194152">University Assistant, Enterprise &amp; Process Engineering, TU Wien, Fall 2023</a>
                
              </td>
            </tr>
            
          </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td>
                <br>
                <p align="right">
                  <span style="font-size: x-small; ">
                    Website template basend on <a href="https://jonbarron.info/">✩</a>.
                  </span>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
